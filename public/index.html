<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>郑桂东的学习地</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="郑桂东的学习地">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="郑桂东的学习地">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="郑桂东的学习地">
  
    <link rel="alternate" href="/atom.xml" title="郑桂东的学习地" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
  

</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">郑桂东的学习地</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" results="0" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post-tackbp" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/12/22/tackbp/" class="article-date">
  <time datetime="2016-12-22T08:41:51.000Z" itemprop="datePublished">2016-12-22</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/12/22/tackbp/">tackbp2014</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h3 id="tackbp"><a href="#tackbp" class="headerlink" title="tackbp"></a>tackbp</h3><p>NIST TAC-KBP2014的实体链接（EL）任务旨在从文本文档的源集合中提取命名实体，并将它们链接到现有知识库（KB）。 还需要EL系统来集群那些没有相应的KB条目的NIL实体。 今年的任务包括以下几个方面：单语英语EL（英语文本到英语KB），跨语言汉语到英语EL（中文到英语KB）和跨语言西班牙语到英语（西班牙语文本 到英语KB）。</p>
<h3 id="conll-yago2003"><a href="#conll-yago2003" class="headerlink" title="conll-yago2003"></a>conll-yago2003</h3><p>CoNLL-2003共享任务数据文件包含由单个空格分隔的四列。 每个词都放在一个单独的行上，每个句子后面有一个空行。 每行上的第一个项目是一个单词，第二个是词性（POS）标记，第三个是句法块标记，第四个是命名实体标记。 块标记和命名实体标记具有I-TYPE的格式，这意味着该单词在TYPE类型的短语内。 只有两个相同类型的短语紧跟在一起，第二个短语的第一个单词将具有标签B-TYPE，以表明它开始一个新的短语。 带标签O的字词不是短语的一部分。 这里是一个例子：<br>   U.N.         NNP  I-NP  I-ORG<br>   official     NN   I-NP  O<br>   Ekeus        NNP  I-NP  I-PER<br>   heads        VBZ  I-VP  O<br>   for          IN   I-PP  O<br>   Baghdad      NNP  I-NP  I-LOC<br>   .            .    O     O </p>
<p>数据由每种语言的三个文件组成：一个训练文件和两个测试文件testa和testb。 第一个测试文件将在开发阶段用于为学习系统找到良好的参数。 第二个测试文件将用于最终评估。 有数据文件可用于英语和德语。 德语文件包含一个额外的列（第二个），它保存每个单词的引理。</p>
<h3 id="aida-ee"><a href="#aida-ee" class="headerlink" title="aida-ee"></a>aida-ee</h3><p>AIDA-EE数据集包含300个文档，9,976个实体名称链接到维基百科（2010-08-17转储）。 文档本身取自GIGAWORD5 [1]数据集的APW部分，包含2010-10-01（开发数据）的150个文档和2010-11-01的150个文档（测试数据）。 由于许可问题，不提供文档内容，只提供实体注释的偏移量。</p>
<p>数据格式</p>
<p>数据集分为两个文件：apw_eng_201010.tsv和apw_eng_201011.tsv，对应于GIGAWORD5数据集中的（解压缩的）apw_eng_201010和apw_ang_201011文件。</p>
<p>每个文件每行包含一个实体作为制表符分隔值，具有以下列含义：</p>
<p>0：原始文件中的字符偏移量（\ n计数为字符） - 需要 - 将原始文件解压缩以使偏移有意义。<br>1：注释名称的完整字符串（由Stanford CoreNLP工具包自动识别，手动更正）<br>2：实体的YAGO2标识符或–OOKBE–（知识库实体，新兴实体）<br>3：维基百科URL（在2010-08-17转储）或–OOKBE–（知识库实体，新兴实体）<br>4：文档ID（仅供参考）</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/12/22/tackbp/" data-id="cix8njgeq00071jjiuoud2kxm" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/note/">note</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-knn" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/12/17/knn/" class="article-date">
  <time datetime="2016-12-17T12:16:01.000Z" itemprop="datePublished">2016-12-17</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/12/17/knn/">knn</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h3 id="特征选择"><a href="#特征选择" class="headerlink" title="特征选择"></a>特征选择</h3><p>好的特征选择能够提升模型性能</p>
<p>特征选择：<br>1.减少特征数量、降维，使模型泛化能力更强，减少过拟合<br>2.增强对特征和特征值之间的理解</p>
<ul>
<li>去掉取值变化小的特征 Removing features with low variance</li>
<li>单变量特征选择Univariate feature selection<br>  单变量特征选择能够对每一个特征进行测试，衡量该特征和响应变量之间的关系，根据得分舍去不好的特征。对于回归和分类问题可以采用卡方检验对特征进行测试。<ul>
<li>Pearson相关系数Pearson Correlation<br>皮尔森相关系数是一种最简单的，能帮助理解特征和响应变量之间关系的方法，该方法衡量的是变量之间的线性相关性，结果的取值区间为[-1，1]，-1表示完全的负相关(这个变量下降，那个就会上升)，+1表示完全的正相关，0表示没有线性相关。Pearson相关系数的一个明显缺陷是，作为特征排序机制，他只对线性关系敏感。如果关系是非线性的，即便两个变量具有一一对应的关系，Pearson相关性也可能会接近0。</li>
<li>互信息和最大信息系数 Mutual information and maximal information coefficient </li>
<li>距离相关系数（Distance correlation）</li>
<li>基于学习模型的特征排序(Model based ranking)<br>这种方法的思路是直接使用你要用的机器学习算法，针对每个单独的特征和响应变量建立预测模型。其实Pearson相关系数等价于线性回归里的标准化回归系数。假如某个特征和响应变量之间的关系是非线性的，可以用基于树的方法（决策树、随机森林）、或者扩展的线性模型等。基于树的方法比较易于使用，因为他们对非线性关系的建模比较好，并且不需要太多的调试。但要注意过拟合问题，因此树的深度最好不要太大，再就是运用交叉验证。</li>
</ul>
</li>
<li>线性模型与正则化<br>###　k-近邻分类器</li>
</ul>
<p>k-近邻分类算法<br>    1．设置参数k,输入待识别样本x;</p>
<pre><code>2. 计算x与每个训练样本的距离
3. 选取距离最小的前k个样本，统计其中包含各个类别的样本数k
4.　class ←　argmax Ki
</code></pre><p>(1)计算已知类别数据集中的点与当前点之间的距离<br>(2)按照距离递增次序排序<br>(3)选取与当前点距离最近的k个点<br>(4)确定k个点所在类别的出现频率<br>(5)返回前k个点出现频率最高的类别作为当前点的预测分类</p>
<h3 id="HMM"><a href="#HMM" class="headerlink" title="HMM"></a>HMM</h3>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/12/17/knn/" data-id="cix8njgen00051jjiafv7h4uk" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/读书笔记/">读书笔记</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-贝叶斯定理" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/12/17/贝叶斯定理/" class="article-date">
  <time datetime="2016-12-17T07:57:24.000Z" itemprop="datePublished">2016-12-17</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/12/17/贝叶斯定理/">模式识别课件</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h3 id="模式识别过程"><a href="#模式识别过程" class="headerlink" title="模式识别过程"></a>模式识别过程</h3><p>输入→数据采集→预处理→特征提取→分类器→分类结果</p>
<p>！<a href="/img/bayes_1.png">模式识别系统</a></p>
<h5 id="识别方法分类："><a href="#识别方法分类：" class="headerlink" title="识别方法分类："></a>识别方法分类：</h5><ul>
<li>产生式模型<br>  假设不同类别的样本满足不同的概率分布，根据样本属于不同类别的概率识别样本。（贝叶斯分类器，GMM，ＨＭＭ，…）</li>
<li>鉴别模型：<br>  利用判别函数对特征空间进行划分，不同区域对应不同的类别。（线性分类器，神经网络分类器，SVM）</li>
</ul>
<h3 id="各种概率及其关系"><a href="#各种概率及其关系" class="headerlink" title="各种概率及其关系"></a>各种概率及其关系</h3><pre><code>先验概率：　P(Wi)
后验概率：　P(Wi|X)
类条件概率：P(X｜Wi)
贝叶斯公式：P(Wi|X)=P(X｜Wi)P(Wi)/P(X)
</code></pre><p>判别准则：<br>    i = argmaxP(Wi|X), 则X∈Wi　<br>    P(Wj|X)=P(X｜Wj)P(Wj)/P(X)<br>    Gj(X)=P(X｜Wj)P(Wj)<br>    i = argmaxGj(X) ,则X∈Wi<br>贝叶斯分类器的错误估计：<br>    ！<a href="/img/bayes_2.png">错误率估计</a></p>
<h3 id="朴素贝叶斯进行的文本分类"><a href="#朴素贝叶斯进行的文本分类" class="headerlink" title="朴素贝叶斯进行的文本分类"></a>朴素贝叶斯进行的文本分类</h3><p>伪代码：<br>    计算每个类别中的文档数目<br>    对每篇训练文档：<br>    　　对每个类别：<br>    　　　　如果词条出现在文档中→增加该词条的计数值<br>    　　　　增加所由词条的计数值<br>    　　对每个类别：<br>    　　　　对每个词条<br>    　　　　　　该词条的数目除以总词条数目得到条件概率<br>    返回每个类别的条件概率</p>
<h3 id="HMM隐马尔科夫模型"><a href="#HMM隐马尔科夫模型" class="headerlink" title="HMM隐马尔科夫模型"></a>HMM隐马尔科夫模型</h3><p>应用领域：识别对象存在着先后次序信息，如语音识别，手势识别，唇读系统等<br>马尔科夫假设：模型在时刻t处于状态wj的概率完全由t-1时刻的状态wi决定，而且与时刻t无关，即：P(w(t)|wT) = P(w(t)|w(t-1))<br>隐Markov模型中，状态是不可见的，在每一个时刻t，模型当前的隐状态输出一个观察值</p>
<p>隐马尔科夫工作原理：<br>    观察序列的产生过程：HMM的内部状态转移过程同Markov模型相同，在每次状态转移之后，由该状态输出一个观察值，只是状态转移过程无法观察到，只能观察到输出的观察值序列<br>    输出概率： 以离散的HMM为例，隐状态可能输出的观察值集合为{v1, v2, …, vK}，第i个隐状态输出第k个观察值的概率为bik。</p>
<p>HMM的三个核心问题：<br>    估值问题：已有一个HMM模型，其参数已知，计算这个模型输出特定的观察序列VT的概率；<br>    解码问题：已有一个HMM模型，其参数已知，计算最有可能输出特定的观察序列VT的隐状态转移序列WT<br>    学习问题：已知一个HMM模型的结构，其参数未知，根据一组训练序列对参数进行训练</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/12/17/贝叶斯定理/" data-id="cix8njgey000e1jjik5jxm1k4" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/读书笔记/">读书笔记</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-ufldl-softmax" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/12/15/ufldl-softmax/" class="article-date">
  <time datetime="2016-12-15T10:43:24.000Z" itemprop="datePublished">2016-12-15</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/dl/">dl</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/12/15/ufldl-softmax/">ufldl_softmax</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h3 id="softmax"><a href="#softmax" class="headerlink" title="softmax"></a>softmax</h3><p><a href="http://ufldl.stanford.edu/wiki/index.php/Softmax%E5%9B%9E%E5%BD%92" target="_blank" rel="external">http://ufldl.stanford.edu/wiki/index.php/Softmax%E5%9B%9E%E5%BD%92</a></p>
<p>softmax回归模型是logistic回归模型在多分类问题上的推广，在多分类问题种，类标签y可以取两个以上的值。softmax回归模型对于诸如mnist手写数字分类10个不同的单个数字问题是很有用的。softmax回归是有监督的。</p>
<p>在logistic回归中，有m个已标记的训练集{（x(1),y(1)）,…,(x(m),y(m))}，logistic回归是针对二分类问题的，类标记y(i)属于{0,1}。假设函数(hypothesis function）可以表示为：<br>    ！<a href="/img/blog_softmax_1.png">1</a><br>将训练模型参数θ，使其能够最小化代价函数：<br>    ！<a href="/img/blog_softmax_2.png">2</a></p>
<p>在多分类中，对于给定的测试输入x,用假设函数针对每一个类别j估算出概率值p(y=j|x).<br>假设函数要输出一个k维的向量（向量元素的和为1）来表示这k个估计的概率值。假设函数hθ（x）形式如下:<br>    ！<a href="/img/blog_softmax_3.png">3</a><br>θ1,θ2,…θk是模型参数。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/12/15/ufldl-softmax/" data-id="cix8njgev000c1jjijlpvs7oe" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/read/">read</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-encoding" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/12/14/encoding/" class="article-date">
  <time datetime="2016-12-14T10:38:34.000Z" itemprop="datePublished">2016-12-14</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/杂/">杂</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/12/14/encoding/">数据预处理:one-hot encoding</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h3 id="One-Hot-Encoding"><a href="#One-Hot-Encoding" class="headerlink" title="One-Hot Encoding"></a>One-Hot Encoding</h3><p>one-hot编码，又称为一位有效编码，对任意给定的状态，状态向量中只有一位为1，其余各位为0。主要是采用N位状态寄存器来对N个状态进行编码，每个状态都由他独立的寄存器位，并且在任意时候只有一位有效。这种状态机的速度与状态的数量无关，只取决于某特定状态的转移数量，速度很快。当状态机的状态增加时，如果使用二编码，那么速度会明显下降，但如果采用独热码，虽然多用了触发器，但由于状态译码简单，节省和简化了组合逻辑电路。<br>一个四种状态：A，B，C，D<br>独热编码就为：0001,0010,0100,1000</p>
<p>在实际的机器学习的应用任务中，特征有时候并不总是连续值，有可能是一些分类值，如性别可分为“male”和“female”。在机器学习任务中，对于这样的特征，通常需要对其进行特征数字化，如有如下三个特征属性：</p>
<pre><code>* 性别：[&quot;male&quot;，&quot;female&quot;]
 * 地区：[&quot;Europe&quot;，&quot;US&quot;，&quot;Asia&quot;]
* 浏览器：[&quot;Firefox&quot;，&quot;Chrome&quot;，&quot;Safari&quot;，&quot;Internet Explorer&quot;]
</code></pre><p>性别的属性是二维的，地区是三维的，浏览器则是四维的，这样，可以采用One-Hot编码的方式对上述的样本“[“male”，”US”，”Internet Explorer”]”编码，“male”则对应着[1，0]，同理“US”对应着[0，1，0]，“Internet Explorer”对应着[0,0,0,1]。则完整的特征数字化的结果为：[1,0,0,1,0,0,0,0,1]。这样导致的一个结果就是数据会变得非常的稀疏。</p>
<pre><code>from sklearn import preprocessing
enc = preprocessing.OneHotEncoder()
enc.fit([[0,0,3],[1,1,0],[0,2,1],[1,0,2]])
array = enc.transform([[0,1,3]]).toarray()
print array 
</code></pre><p>结果：[[ 1.  0.  0.  1.  0.  0.  0.  0.  1.]]</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/12/14/encoding/" data-id="cix8njgec00011jji419i6nep" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/read/">read</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-ubuntu-windows同步hexo" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/12/13/ubuntu-windows同步hexo/" class="article-date">
  <time datetime="2016-12-13T11:33:37.000Z" itemprop="datePublished">2016-12-13</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/杂/">杂</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/12/13/ubuntu-windows同步hexo/">ubuntu&amp;windows同步hexo</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>在windows和ubuntu上根据网上相关教程均已配好环境。</p>
<h2 id="windows上"><a href="#windows上" class="headerlink" title="windows上"></a>windows上</h2><p>使用git<br>在hexo初始化所在的博客文件夹下初始化仓库：<br>    <code>git init</code><br>然后在github上new 一个 repositories,假设它的地址为:git@github.com:user/blog.git,输入<br>    <code>git remote add origin git@github.com:user/blog.git</code></p>
<p>添加本地所有文件到仓库,并添加更新说明：<br>    <code>git add .</code><br>    <code>git commit -m &#39;commit&#39;</code><br>同步到git上取：<br>    <code>git push -u origin master</code></p>
<h2 id="ubuntu"><a href="#ubuntu" class="headerlink" title="ubuntu"></a>ubuntu</h2><p>假设这时候已经将windows上的内容备份到git上，</p>
<p>在ubuntu下新建一个文件夹：<br>    <code>mkdir blog</code></p>
<p>在blog中初始化仓库：<br>    <code>git init</code><br>将本地文件和线上仓库映射起来<br>    <code>git remote add origin git@github.com:user/blog.git</code><br>从网上拉取内容,reset是不做任何合并处理，强制将本地内容指向刚刚同步下来的云端内容：<br>    <code>git fetch --all
     git reset --hard origin/master</code></p>
<h2 id="更新文章的同步操作"><a href="#更新文章的同步操作" class="headerlink" title="更新文章的同步操作"></a>更新文章的同步操作</h2><p>在ubunut下写完文章后更新上去<br>    <code>git add .
     git commit -m &#39;更新内容&#39;
     git push</code></p>
<p>在windows上使用：<br>    <code>git pull</code></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/12/13/ubuntu-windows同步hexo/" data-id="cix8njgeu000a1jjidgupcoos" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/learn/">learn</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-图方法命名实体消歧" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/12/13/图方法命名实体消歧/" class="article-date">
  <time datetime="2016-12-13T11:31:40.066Z" itemprop="datePublished">2016-12-13</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>#基于图方法的命名实体消歧</p>
<p>###摘要</p>
<ol>
<li>首先对知识库的预处理，需要利用知识库中的实体关系对候选实体进行拓展，预处理从三元组的表示形式和数据集筛选两个角度进行，通过预处理，去除对消歧无用的信息，减少噪声数据<br>三元组表示时，主要对三元组的实体表示进行缩减，并对异常编码处理<br>数据集上，针对不同的数据集提醒进行分析，对数据集中的三元组进行过滤</li>
<li>实体消歧主要步骤是生成候选实体和名实体消歧<br>先从文本中的实体指称生成候选，基于字符串相似度的方法和基于知识库的方法两个角度对实体指称生成候选，字符串相似度方法主要从候选实体的扩充和筛选两个方面，基于知识库的方法主要有基于规则的方法和基于先验概率的方法。通过对不同候选生成方法的效果进行对比，最终对几种方法进行组合。</li>
<li><p>候选实体生成之后是名实体消歧</p>
<ul>
<li>利用知识库中的实体关系对候选实体进行拓展，候选实体之间形成互相连通的实体网络图</li>
<li>在网络图上采用链接分析算法，为候选实体评分从而实现消歧<br>对实体的拓展策略设计拓展采用的实体关系，拓展的实体路径长度，上下文粒度的选择以及对实体指称进行消歧是采用同时决策还是依次进行决策。</li>
</ul>
<p>名实体消歧，图方法，DBpedia，知识库<br>###绪论</p>
<p>命名实体消歧：将文本中具有多个含义的实体指称去除歧义。并将其链接到知识库中的唯一实体，从而达到消歧目的。<br>名实体：主要是包括人名，地名，机构名等，在句子中往往是作为主语宾语等成分<br>名实体消歧意义：<br> 实体消歧改进搜索引擎的查询效果<br> 集成互联网信息，易于挖掘有用信息<br> 拓展知识库内容<br>维基百科中积累大量的名实体信息，大量的名实体消歧任务以及维基百科作为背景任务，将文本中的名实体与维基百科标题想对应，实体消歧也称维基化（Wikification）；实体消歧相似的另一个任务是实体链接，主要区别，实体链接除了确定名实体在知识库中对应的实体，还需要对知识库中不存在的名实体通过聚类进行处理<br>实体消歧的目的是从文本中可能具有歧义的名实体映射到某个无歧义的概念。文本中的名实体被称为实体指称(mention，通常是目标实体的缩写、简称、绰号甚至是错误拼写),是某概念在文本中的具体引用形式。而无歧义的概念使用知识库中的实体来表示。实体消歧要做的就是对文本中的所有实体指称找到知识库中与之唯一对应的目标实体。</p>
<p>实体消歧：<br>× 根据实体指称字符串，通过候选生成算法获得该实体指称所有可能的实体（称候选实体），<br>× 通过消歧算法对候选实体进行排序，从而确定实体指称对应的目标实体</p>
<p>DBpedia知识库，结构化的维基百科知识库，它通过语义网络技术对维基百科内容进行组织，DBpedia由RDF三元组构成，三元组包含实体以及实体之间的关系。</p>
<p>实体消歧策略：</p>
<ul>
<li>局部策略 (local) ,不同的实体指称的消歧决策是相互独立，实体指称通过其所在文本中的上下文特征和每个候选实体计算匹配程度从而确定目标实体</li>
<li>全局策略 (global)，同一文本中出现的实体是关于某个主题的，相互之间存在语义关联，具有某种程度的内聚性，同一文本中的不同实体指称的决策是相互依赖的</li>
<li>集体策略（collective）<br>实体消歧常用特征：</li>
</ul>
<ol>
<li>局部特征：</li>
</ol>
<ul>
<li>上下文相似度（Context Similarity）<br>为实体指称设定一个上下文窗口，将窗口内的文本和实体对应的维基百科文本计算余弦相似度</li>
<li>先验概率（Prior Probability）<br>p(c|m),m表示实体指称,c表示候选实体。给定一个实体指称m其对应的目标实体是c的概率。该概率通过统计所有维基百科正文中出现的锚文本超链接字符串 m 和链接所指向的维基百科页面的标题的对应关系得出。先验概率来自由维基百科志愿者编写的超链接,因此具有较高的可靠性,常被用于作为实体消歧的基线系统。</li>
<li>实体流行度（Popularity）<br>统计每个实体的维 基 百 科 入 链 数 并 除 以 所 有 维 基 百 科 链 接 数 目 , 最 终 得 到 实 体 的 流 行 度</li>
</ul>
<ol>
<li>全局特征</li>
</ol>
<ul>
<li>链接重叠（Link Overlap）<br>链接重叠采用的资源主要是实体的维基百科页面中的入链集合和出链集合,该特征认为具有较多共有链接的实体之间具有较高的相关度。评估的标准有谷歌距离和 Jaccard 相似系数等。</li>
<li>语义相关度（Semantic Relatedness）<br>利用实体的维基百科类别和信息框数据</li>
</ul>
</li>
</ol>
<h3 id="知识库数据集和预处理"><a href="#知识库数据集和预处理" class="headerlink" title="知识库数据集和预处理"></a>知识库数据集和预处理</h3><p>语义网络（Semantic Web），在互联网数据之间创造了链接，方便浏览这个网络。<br>资源描述框架（Resource Description Framework,RDF），统一资源标识符(Uniform Resource Identifiers,URIs)<br>一条RDF语句由三个URL组成的三元组（triple）表示，三元组的各个部分依次被称为主语、谓语、宾语。RDF三元组通常用于陈述某一事实。三元素之间以空格分割,使用“.”作为结束符。RDF实体一般使用缩写，dbr:通常为实体的前缀,后跟实体名。dbo:代表本体,通常做为本体类或者属性的前缀。rdfs:后跟subclass,property 等表示本体类别间的关系或者属性,通常用于描述类别。rdf:后跟 type,可以作为谓语定义实体的类别。skos:用于描述概念间的语义关系</p>
<p>DBpedia知识库由一系列分散的数据集构成，这些数据集使用不同的DBpedia抽取器（DBpedia extractors）抽取自维基百科页面不同的部分</p>
<pre><code>- labels_en.nt由labels抽取器抽取自维基百科页面的标题部分
- short_abstracts_en.nt由abstract抽取器抽取自维基百科正文的首段
- disambiguation_en.nt抽取自维基百科消歧页面
- redirect_en.nt 抽取自维基百科的重定向页面,现实中存在同一事物具有不同别名的情况
- page_links.nt 抽取自维基百科词条页面的链接信息。
- article_categories_en.nt 抽取自维基百科页面底端的维基百科类别
- skos_categories_en.nt 文件中每个三元组主语和宾语是维基百科类别实体,谓语是两个实体之间的关系
- instance_types_en.nt 中保存的是实体和实体类别间的关系
- mappingbased_properties_en.nt 存储的是从维基百科信息框抽取的属性信息
- persondata_en.nt 专门从维基百科页面抽取的人物信息框中的内容
- dbpedia_2014.owl 中存储的是本体类,定义了类别之间的关系以及每个类别的属性
</code></pre>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/12/13/图方法命名实体消歧/" data-id="cix8njgf1000l1jjiwypn8aws" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-hello-world" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/12/13/hello-world/" class="article-date">
  <time datetime="2016-12-13T11:31:40.062Z" itemprop="datePublished">2016-12-13</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/12/13/hello-world/">Hello World</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>Welcome to <a href="https://hexo.io/" target="_blank" rel="external">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="external">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="external">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="external">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ hexo new <span class="string">"My New Post"</span></div></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="external">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ hexo server</div></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="external">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ hexo generate</div></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="external">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ hexo deploy</div></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="external">Deployment</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/12/13/hello-world/" data-id="cix8njgee00021jjig3zomzl8" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-决策树" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/12/13/决策树/" class="article-date">
  <time datetime="2016-12-13T11:31:40.062Z" itemprop="datePublished">2016-12-13</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>#decision tree</p>
<p>###决策树的工作原理<br>在决策树中，每个叶节点都赋予一个类标号。非终结点(non-terminal node)（包括根结点和内部结点）包含属性测试条件，以分开具有不同特性的记录。<br>一旦构造了决策树，对检验记录进行分类就相当容易了，从数的根节点开始，将测试条件用与检验记录，根据检测结果选择适当的分支。沿着该分支或者到达另一个内部结点，使用新的测试条件，或者到达一个叶节点。到达叶节点后，叶节点的类称号就被赋值给该检验记录</p>
<p>###如何建立决策树<br>原则上讲，对于给定的数据集，可以构造的决策树的数目达指数级。为了能够在合理的时间内构造出具有一定准确率率的次最优决策树，开发了很多有效算法，这些算法一般都采用贪心策略，在选择划分数据的属性时，采取一系列局部最优决策来构造决策数，Hunt算法就是这种算法。由此衍生了一些：ID3,C4.5和CART<br><strong>1. Hunt算法</strong><br>在Hunt算法中，通过训练记录相继划分成较纯的子集，以递归方式建立决策树。设Dt是与结点t相关联的训练记录集，而y={y1,y2,…,y3}是类标号，hunt算法递归定义为：<br>    （1）如果Dt中所有记录都属于同一个类yt，则t是叶结点，用yt标记<br>    （2）如果Dt中包含属于多个类的记录，则选择一个属性测试条件（attribute test condition），将记录划分成较小的子集。对于测试条件的每个输出，创建一个子女结点，并根据测试结果将Dt中的记录分布到子女结点中。然后，对与每个子女结点，递归调用该算法。<br>如果属性值的每种组合都在训练数据中出现，且每种组合具有唯一的类标号，则Hunt是有效的。但这种条件过于苛刻，需要附加条件来处理：<br>    （1）算法的第二步所创建的子女结点可能为空，即不存在与这些结点相关联的记录。如果没有一个训练记录包含与这样的结点相关联的属性值组合，这种情形可能发生。这时，该结点成为叶结点，类标号为其父节点上训练记录中的多数类<br>    （2）在第二步中，如果与Dt相关联的所有记录都具有相同的属性值（目标属性除外），则不可能进一步划分这些记录。在这种情况下，该结点为叶节点，其标号为与该结点相关联的训练记录中的多数类。</p>
<p><strong>2. 决策树的归纳的设计问题</strong><br>     （1）<strong>如何分裂训练记录？</strong>   树增长过程的每个递归步都必须选择一个属性测试条件，将记录划分成较小的子集。为了实现这个，算法必须提供为不同类型的属性指定测试条件的方法，并且提供评估每种测试条件的客观度量<br>    （2）<strong>如何停止分裂过程？</strong>   需要有结束条件，以终止决策树的生长过程。一个可能的决策是分裂结点，直到所有的记录都属于同一个类，或者所有的记录都具有相同的属性值。尽管两个结点结束条件对于结束决策树归纳算法都是充分的，但是可以使用其他的标准提前终止树的生长过程。</p>
<p>###表示属性测试条件的方法<br>决策数归纳算法必须为不同类型的属性提供表示属性测试条件和对应输出的方法<br><strong>二元属性</strong>     二元属性的测试条件产生两个可能的输出<br><strong>标称属性</strong>     由于标称属性有多个属性值，它的测试条件可以用两种方法表示。<br><strong>序数属性</strong>     序数属性也可产生二元或多路划分，只要不违背序数属性值的有序性，就可对属性值进行分组。<br><strong>连续属性</strong>     对于连续属性来说，测试条件可以是二元输出的比较测试（A<v）或（a>=v）,也可以是具有形如Vi&lt;=A&lt;Vi+1(i=1,…,k)输出的范围查询。</v）或（a></p>
<p>###选择最佳划分的度量<br>有很多度量可以用来确定划分记录的最佳方法，这些度量用划分前和划分后记录的类分布定义。<br>选择最佳的划分的度量通常是根据划分后子女结点不纯性的程度。不纯的程度越低，类分布就月倾斜。<br>信息熵，基尼指数，分类误差<br>基尼指数：选择小的</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/12/13/决策树/" data-id="cix8njgf0000i1jji3pbrbaqe" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-dataming" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/12/13/dataming/" class="article-date">
  <time datetime="2016-12-13T11:31:40.062Z" itemprop="datePublished">2016-12-13</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>#分类：基本概述、决策树与模型评估</p>
<p>###预备知识</p>
<pre><code>分类（classification）分类任务就是通过学习得到一个目标函数（target function）f,把每个属性集x映射到一个预先定义的类标号y
目标函数也称为分类模型（classification model）
</code></pre><p>分类模型的性能根据模型正确和错误预测的检验记录计数进行评估，这些计数存放在称作<em>混淆举证（confusion matrix）</em>的表格中</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/12/13/dataming/" data-id="cix8njge700001jjiyvaxbro4" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  


  <nav id="page-nav">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="extend next" rel="next" href="/page/2/">__('next') &raquo;</a>
  </nav>
</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/dl/">dl</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/杂/">杂</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/learn/">learn</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/note/">note</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/read/">read</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/读书笔记/">读书笔记</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/learn/" style="font-size: 10px;">learn</a> <a href="/tags/note/" style="font-size: 10px;">note</a> <a href="/tags/read/" style="font-size: 15px;">read</a> <a href="/tags/读书笔记/" style="font-size: 20px;">读书笔记</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/12/">December 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/10/">October 2016</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2016/12/22/tackbp/">tackbp2014</a>
          </li>
        
          <li>
            <a href="/2016/12/17/knn/">knn</a>
          </li>
        
          <li>
            <a href="/2016/12/17/贝叶斯定理/">模式识别课件</a>
          </li>
        
          <li>
            <a href="/2016/12/15/ufldl-softmax/">ufldl_softmax</a>
          </li>
        
          <li>
            <a href="/2016/12/14/encoding/">数据预处理:one-hot encoding</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2016 Zheng GuiDong<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>

  </div>
</body>
</html>