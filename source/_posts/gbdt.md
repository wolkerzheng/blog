---
title: gbdt
date: 2017-01-06 17:25:04
tags:
---
## Boosting
Boosting是彝族可将弱学习器提升为强学习器的算法.这族算法的工作机制类似:先从初始训练集训练出一个基学习器,在根据学习器的表现对训练样本分布进行调整,使得先前基学习器做错的训练样本在后续受到更多关注,然后基于调整后的样本分布来训练下一个基学习器;如此重复进行,直至基学习器数目达到事先指定的值T,最终将这T个基学习器进行权结合.
## GBDT
GBDT(Gradient Boosting Decision Tree)是一种迭代的决策树算法,该算法由多棵决策树组成,通过所有树进行投票来进行分类.这是一种泛化能力(generalization)比较强的算法.

GBDT是一个加性回归模型,通过boosting迭代的构造一组弱学习器,相对LR的优势,如不需要做特征的归一化,自动进行特征选择,模型可解释性比较好,可以适应多种损失函数如,Squareloss,LogLoss等.每一次建立模型是在之前建立模型的损失函数的梯度下降方向
GBDT的核心在于,每一棵树学的是之前所有树结论和的残差,残差为与预测值的差值.

## 随机森林(Random Forest)

随机森林是Bagging的一个扩展变体.RF在以决策树为基学习器构建Bagging集成 的基础上,进一步在决策树的训练过程中引入了随机属性选择.传统决策树在选择划分属性时是在当前结点的属性集合(假定有d个属性)中选择一个最优属性;而在随机森林中,对基决策树的每个结点,先从该结点的属性集合中随机选择一个包含k个属性的子集,然后再从这个子集中选择一个最优属性用户划分.一个情况下,k=log2d
