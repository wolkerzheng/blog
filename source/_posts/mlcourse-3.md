---
title: mlcourse-3
date: 2017-01-05 19:25:28
tags:
---
## 决策树
### 信息增益

	![enter description here][1]


  [1]: ./img/ml3_1.png "ml3_1.png"
  其中,p,n是结点node德尔正\反例个数.A要扩展结点node的属性,Pi,Ni 是C被A划分成V个子集{C1,...,Cv}的正\反例个数.



### 决策树学习的常见问题

 - 不相关属性
 - 不充足属性
   两类例子具有相同的属性值.没有任何属性可进一步扩展决策树.哪类例子多,叶节点标为哪类
 - 未知属性值
	 - 最通常值方法
	 - 决策树方法:把未知属性作为"类",原来的类作为"属性"
	 - bayesian方法
	 - 按比例将未知属性值例子分配到各子集中:属性A由v个值{A1,....,Av},A值等于Ai的例子数Pi和ni,未知属性值例子数分别为Pu和Nu,在生成决策树时Ai的例子数Pi+pu·ratio   ni+nu·ratio


## 规则学习算法

一个例子e = <v1,...,vn> 满足选择子(公式,规则)的条件,也称作选择子(公式,规则)覆盖该例子.

普化(generalize):减少规则的约束,使其覆盖更多的训练例子叫普化

特化(specialize):增加规则的约束,使其覆盖训练例子较少叫特化

一致:只覆盖正例不覆盖反例的规则被称为是一致的

完备:覆盖所有正例的规则被称为完备的

## gs算法

GS算法
输入:例子集
输出:规则
原则:(a)从所有属性中选出覆盖正例最多的属性
		(b)在覆盖正例数相同的情况下,优先选择覆盖反例少的属性值

设PE,NE是正例，反例的集合。 PE’,NE’是临时正，反例集。CPX表示公式，F表示规则（概念描述）。
(1) F←false;
(2) PE’ ←PE, NE’ ←NE, CPX←true;
(3) 按上述(a) (b)两原则选出一个属性值V 0 , 设V 0 为第j0个属性的取值，CPX←CPX∧ [Xj0=V0]
(4) PE’ ← CPX覆盖的正例，NE’ ← CPX覆盖的反例，如果NE’不为空，转(3);
            否则，继续执行(5);
(5) PE←PE\PE’, F ←F ∨CPX, 如果PE =∅   ,停止，否则转(2);


## AQ算法
输入:例子集,参数#SQL,#CONS.Star的容量m,优化标准
输出:规则

1) Pos和NEG分布代表正例和反例的集合
    ①从Pos中随机地选择一例子
	② 生成例子e相对于反例集NEG的一个约束Star(reduced star),G(e|NEG,m) , 其中元素不多于m个。
	③ 在得到的star中，根据设定的优化标准LEF找出一个最优的公式D。
	④ 若公式D完全覆盖集合Pos,则转⑥
	⑤ 否则，减少Pos的元素使其只包含不被D覆盖的例子。从步骤①开始重复整个过程。
	⑥ 生成所有公式D的析取，它是一个完备且一致的概念描述。
2) Star生成: Induce方法
	① 例子e的各个选择符被放入PS(partial star)中,将ps中的元素按照各种标准排序.
	②在ps中保留最优的m个选择符.
	③对ps中的选择符进行完备性和一致性检查,从ps中取出完备一致的描述放入SOLUTION表中,若SOLUTION表的大小大于等于参数#SOL,则转⑤.一致但不完备的描述从ps中取出放入表CONSISTENT中,若CONSISTENT表的大小大于等于参数#COS,则转⑤;
	④对每个表达式进行特殊化处理,所有得到的表达式根据优化标准排列,仅保留m个最优的.重复步骤③, ④.
	⑤得到的一般化描述按优先标准排序,保留m个最优的表达式构成约束Star(e|NEG,m).


### 扩张矩阵
