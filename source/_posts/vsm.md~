---
title: vsm
date: 2017-01-05 20:59:57
tags:
---
### vsm
VSM(Vector Space Model):
把文本内容的处理简化为向量空间中的向量运算,并且它以空间上的相似度表达语义的相似度,直观易懂.当文档被表示为文档空间的向量,就可以通过计算向量之间的相似度来度量文档间的相似性.文本处理中最常用的相似度量方法是余弦距离
M个无序特征项ti，词根/词/短语/其他每个文档dj可以用特征项向量来表示（a1j,a2j，…，aMj）权重计算，N个训练文档AM*N= (aij) 文档相似度比较1）Cosine计算，余弦计算的好处是，正好是一个介于0到1的数，如果向量一致就是1，如果正交就是0，符合相似度百分比的特性,余弦的计算方法为，向量内积/各个向量的模的乘积.2）内积计算，直接计算内积，计算强度低，但是误差大。
向量空间模型 （或词组向量模型) 是一个应用于信息过滤，信息撷取，索引 以及评估相关性的代数模型。SMART是首个使用这个模型的信息检索系统。
文件（语料）被视为索引词（关键词）形成的多次元向量空间， 索引词的集合通常为文件中至少出现过一次的词组。
搜寻时，输入的检索词也被转换成类似于文件的向量，这个模型假设，文件和搜寻词的相关程度，可以经由比较每个文件(向量）和检索词（向量）的夹角偏差程度而得知。
实际上，计算夹角向量之间的余弦比直接计算夹角容易：
余弦为零表示检索词向量垂直于文件向量，即没有符合，也就是说该文件不含此检索词。
通过上述的向量空间模型，文本数据就转换成了计算机可以处理的结构化数据，两个文档之间的相似性问题转变成了两个向量之间的相似性问题。

向量空间模型的关键在于特征向量的选取和特征向量的权值计算两个部分.

1．文档向量的构造
　　对于任一文档d_j ∈ D，我们可以把它表示为如下t维向量的形式：

\overline{d}_j =(w_{1j},w_{2j},\cdots,w_{tj})
  向量分量wtj代表第i个标引词ki在文档dj中所具有的权重，t为系统中标引词的总数。在布尔模型中，wtj的取值范围是{0，1}；在向量空间模型中，由于采用“部分匹配”策略，wtj的取值范围是一个连续的实数区间[0，1]。

### TF-IDF
TF-IDF（term frequency–inverse document frequency）是一种用于信息检索与数据挖掘的常用加权技术。
    词频(TF) = 某个词在文章中的出现次数
标准化:
    词频(TF) = 某个词在文章中的出现次数/文章的总词数
计算逆文档频率:
    逆文档频率(IDF) = log(语料库的文档总数/包含该词的文档数+1)
如果一个词越常见，那么分母就越大，逆文档频率就越小越接近0。分母加1，是为了避免分母为0（即所有文档都不包含该词）。log表示对得到的值取对数。
    TF-IDF = 词频(TF) * 逆文档频率(IDF)
所以,TF-IDF与一个词在文档中的出现次数成正比,与该词在整个语言中的出现次数成反比.
TF-IDF权重计算方法经常会和余弦相似度(cosine similarity)一同使用於向量空间模型中，用以判断两份文件之间的相似性。
找出相似文章:
    （1）使用TF-IDF算法，找出两篇文章的关键词；
　　（2）每篇文章各取出若干个关键词（比如20个），合并成一个集合，计算每篇文章对于这个集合中的词的词频（为了避免文章长度的差异，可以使用相对词频）；
　　（3）生成两篇文章各自的词频向量；
　　（4）计算两个向量的余弦相似度，值越大就表示越相似。
### 词袋模型(BoW)
该模型忽略掉文本的语法和语序等要素，将其仅仅看作是若干个词汇的集合，文档中每个单词的出现都是独立的。BoW使用一组无序的单词(words)来表达一段文字或一个文档.
