---
title: 模式识别课件
date: 2016-12-17 15:57:24
tags: 读书笔记
---

### 模式识别过程

输入→数据采集→预处理→特征提取→分类器→分类结果

！[模式识别系统](/img/bayes_1.png)


##### 识别方法分类：
* 产生式模型
	假设不同类别的样本满足不同的概率分布，根据样本属于不同类别的概率识别样本。（贝叶斯分类器，GMM，ＨＭＭ，...）
* 鉴别模型：
	利用判别函数对特征空间进行划分，不同区域对应不同的类别。（线性分类器，神经网络分类器，SVM）

### 各种概率及其关系

	先验概率：　P(Wi)
	后验概率：　P(Wi|X)
	类条件概率：P(X｜Wi)
	贝叶斯公式：P(Wi|X)=P(X｜Wi)P(Wi)/P(X)

判别准则：
	i = argmaxP(Wi|X), 则X∈Wi　
	P(Wj|X)=P(X｜Wj)P(Wj)/P(X)
	Gj(X)=P(X｜Wj)P(Wj)
	i = argmaxGj(X) ,则X∈Wi
贝叶斯分类器的错误估计：
	！[错误率估计](/img/bayes_2.png)
	

### 朴素贝叶斯进行的文本分类

伪代码：
	计算每个类别中的文档数目
	对每篇训练文档：
	　　对每个类别：
	　　　　如果词条出现在文档中→增加该词条的计数值
	　　　　增加所由词条的计数值
	　　对每个类别：
	　　　　对每个词条
	　　　　　　该词条的数目除以总词条数目得到条件概率
	返回每个类别的条件概率

### HMM隐马尔科夫模型

应用领域：识别对象存在着先后次序信息，如语音识别，手势识别，唇读系统等
马尔科夫假设：模型在时刻t处于状态wj的概率完全由t-1时刻的状态wi决定，而且与时刻t无关，即：P(w(t)|wT) = P(w(t)|w(t-1))
隐Markov模型中，状态是不可见的，在每一个时刻t，模型当前的隐状态输出一个观察值

隐马尔科夫工作原理：
	观察序列的产生过程：HMM的内部状态转移过程同Markov模型相同，在每次状态转移之后，由该状态输出一个观察值，只是状态转移过程无法观察到，只能观察到输出的观察值序列
	输出概率： 以离散的HMM为例，隐状态可能输出的观察值集合为{v1, v2, …, vK}，第i个隐状态输出第k个观察值的概率为bik。

HMM的三个核心问题：
	估值问题：已有一个HMM模型，其参数已知，计算这个模型输出特定的观察序列VT的概率；
	解码问题：已有一个HMM模型，其参数已知，计算最有可能输出特定的观察序列VT的隐状态转移序列WT
	学习问题：已知一个HMM模型的结构，其参数未知，根据一组训练序列对参数进行训练



